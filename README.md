# Project: Spinal cord fMRI analysis at 7T

## Overview
Processing of spinal cord functional data acquired at 7T.

---

## Getting Started

### Set up your project paths

Create a folder that will contain the code of this repository as well as the source and processed data, then define the variable in SHELL:

```bash
export PATH_PROJECT=<PATH_TO_PROJECT>
```

### Download data ğŸ“€

See: https://openneuro.org/datasets/ds007067/download

<details>
<summary>Files are organized according to the BIDS standard.</summary>

```
â”œâ”€â”€ spine_7t_fmri_analysis  # GitHub repository
â”‚   â”œâ”€â”€ code
â”‚     â”œâ”€â”€ convert_data
â”‚     â”‚   â”œâ”€â”€ 00_convert_mriData.sh
â”‚     â”‚   â””â”€â”€ ...
â”‚     â”œâ”€â”€ ...
â”‚   â”œâ”€â”€ config
â”‚     â”œâ”€â”€ config_spine_7t_fmri.json
â”‚     â”œâ”€â”€ participants.tsv
â”‚     â””â”€â”€ ...
â”‚   â”œâ”€â”€ template
â”‚     â”œâ”€â”€ ...
â”‚   â””â”€â”€ log
â”‚       â”œâ”€â”€ ...
â”œâ”€â”€ spine_7t_fmri_data # Data directory
â”‚   â”œâ”€â”€ derivatives
â”‚   â”‚   â”‚   â”œâ”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ manual  # Manually corrected files
â”‚   â”‚   â”‚   â””â”€â”€ sub-100
â”‚   â”‚   â”‚       â”œâ”€â”€ anat
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ sub-100_T2star_space-orig_label-ivd_mask.nii.gz
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ sub-100_T2star_space-orig_label-ivd_mask.nii.gz
â”‚   â”‚   â”‚       â””â”€â”€ func
â”‚   â”‚   â”‚           â”œâ”€â”€ task-motor_acq-shimBase+3mm
â”‚   â”‚   â”‚           â”‚   â”œâ”€â”€ sub-100_task-motor_acq-shimBase+3mm_bold_moco_mean_seg.nii.gz
â”‚   â”‚   â”‚           â”‚   â”œâ”€â”€ sub-100_task-motor_acq-shimBase+3mm_bold_tmean_centerline.csv
â”‚   â”‚   â”‚           â”‚   â””â”€â”€ sub-100_task-motor_acq-shimBase+3mm_bold_tmean_centerline.nii.gz
â”‚   â”‚   â”‚           â”œâ”€â”€ ...
â”‚   â”‚   â””â”€â”€ processing
â”‚   â”‚       â”œâ”€â”€ preprocessing
â”‚   â”‚       â”‚   â”œâ”€â”€ QC  # QC reports
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ ...
â”‚   â”‚       â”‚   â””â”€â”€ sub-100
â”‚   â”‚       â”‚       â”œâ”€â”€ anat
â”‚   â”‚       â”‚       â”‚   â”œâ”€â”€ sct_deepseg
â”‚   â”‚       â”‚       â”‚   â”‚   â”œâ”€â”€ sub-100_T2star_seg.json
â”‚   â”‚       â”‚       â”‚   â”‚   â””â”€â”€ sub-100_T2star_seg.nii.gz
â”‚   â”‚       â”‚       â”‚   â”œâ”€â”€ sct_label_vertebrae
â”‚   â”‚       â”‚       â”‚   â”‚   ...
â”‚   â”‚       â”‚       â”‚   â”œâ”€â”€ sct_register_to_template
â”‚   â”‚       â”‚       â”‚   â”‚   ...
â”‚   â”‚       â”‚       â”‚   â””â”€â”€ sub-100_T2star.nii.gz
â”‚   â”‚       â”‚       â””â”€â”€ func
â”‚   â”‚       â”‚           â”œâ”€â”€ task-motor_acq-shimBase+3mm
â”‚   â”‚       â”‚           â”‚   â”œâ”€â”€ sct_deepseg
â”‚   â”‚       â”‚           â”‚   â”‚   â”œâ”€â”€ sub-100_task-motor_acq-shimBase+3mm_bold_moco_mean_seg.json
â”‚   â”‚       â”‚           â”‚   â”‚   â””â”€â”€ sub-100_task-motor_acq-shimBase+3mm_bold_moco_mean_seg.nii.gz
â”‚   â”‚       â”‚           â”‚   â”œâ”€â”€ sct_fmri_moco
â”‚   â”‚       â”‚           â”‚   â”‚   ...
â”‚   â”‚       â”‚           â”‚   â”œâ”€â”€ sct_get_centerline
â”‚   â”‚       â”‚           â”‚   â”‚   ...
â”‚   â”‚       â”‚           â”‚   â”œâ”€â”€ sct_propseg
â”‚   â”‚       â”‚           â”‚   â”‚   ...
â”‚   â”‚       â”‚           â””â”€â”€ task-motor_acq-shimSlice+3mm
â”‚   â”‚       â”‚               ...
â”‚   â”‚       â””â”€â”€ ...  # Other processing steps (denoising, first-level analysis, etc)
â”‚   â”œâ”€â”€ dataset_description.json
â”‚   â”œâ”€â”€ sub-100
â”‚   â”‚   â”œâ”€â”€ anat
â”‚   â”‚   â”‚   â”œâ”€â”€ sub-100_T2star.json
â”‚   â”‚   â”‚   â””â”€â”€ sub-100_T2star.nii.gz
â”‚   â”‚   â””â”€â”€ func
â”‚   â”‚       â”œâ”€â”€ sub-100_task-motor_acq-shimBase+3mm_bold.json
â”‚   â”‚       â”œâ”€â”€ sub-100_task-motor_acq-shimBase+3mm_bold.nii.gz
â”‚   â”‚       â””â”€â”€ ...
â”‚   â”œâ”€â”€ sourcedata  # Original DICOM and behavioral data
â”‚   â”‚   â”œâ”€â”€ sub-100
â”‚   â”‚   â”‚   â”œâ”€â”€ beh
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ *.csv
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ *.log
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ *.psydat
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”‚   â”œâ”€â”€ mri
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ 01-localizer_iso_ND
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ *.dcm
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”‚   â”œâ”€â”€ ...
â”‚   â”‚   â””â”€â”€ pmu
â”‚   â”‚       â”œâ”€â”€ ...
```

</details>

Define variable:
```bash
export PATH_DATA="${PATH_PROJECT}/ds007067"
```

### Clone repository

```bash
git clone https://github.com/CarolineLndl/spine_7t_fmri_analysis.git
export PATH_CODE="${PATH_PROJECT}/spine_7t_fmri_analysis"
```

### Dependencies ğŸ”—

#### External dependencies

- [Spinal Cord Toolbox v7.2](https://spinalcordtoolbox.com/en/latest/user_section/installation.html)
- [FSL](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FslInstallation)
- [Conda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html)

#### Setup the conda environment

Your environment should include:
- Python (tested with 3.10.14, but other versions could work)

Create the appropriate conda environment:

```bash
conda create --name spine_7T_env_py10 python=3.10
conda activate spine_7T_env_py10
pip install -r "${PATH_CODE}/config/requirements.txt"
```

---

## Analysis Pipeline âš™ï¸

<details><summary>Here is a brief description of the files used for data analysis.</summary>

- **`code/`**: Functions and code to run the analyses. Do not modify the file.
  - `preprocessing.py` > library of preprocessing functions
  - `preprocessing_workflow.py` > orchestrates preprocessing steps using the functions
  - `run_all_processing.sh` > shell script to launch any combination of workflows (so far only one workflow)
  - **`convert_data/`**: Scripts to convert raw mri and physio data into BIDS format.
- **`config/`**: Configuration files for paths and parameters.
  - `config_spine_7t_fmri.json` is used by `preprocessing_workflow.py`
  - `participants.tsv` contains demographical information and important info for preprocessing (*e.g.,* slice number for vertebrae labeling initiation)
- **`template`**: Used for analyses; do not modify.
- **`log`**: Log files generated during processing run from bash script (the folder is not tracked by git).

</details>

Run the pipeline:

```bash
bash "${PATH_CODE}/code/run_all_processing.sh" --path-data "${PATH_DATA}" --path-code "${PATH_CODE}" --ids "${IDs[@]}" --tasks motor --preprocess
```

- Runs preprocessing steps automatically with output log from STDOUT.
- By default all the steps will not be rerun if some outputs already exist. If manual corrections were made, these files will be used as input for subsequent steps. Use --redo to force rerunning all the steps even if some outputs already exist.
- If you have already setup `PATH_CODE` and `PATH_DATA`, you don't need to specify `--path-data` and `--path-code`.
- Specify individuals to process (`--ids 090 101 106`) or `IDs=(090 101 106)` and (`--ids "${IDs[@]}"`) , the default option run preprocessing on all participants in the `participants.tsv`.
- Specify task to process (`--tasks` `motor` or `rest`), the default option runs preprocessing on all tasks defined in the `config_file_7t_fmri.json`

> [!WARNING]  
> Each step manually modified will imply that all subsequent steps need to be re-run.

### Visual check and manual corrections âœï¸

<details>
<summary>For more details, click to expand </summary>

  - **I.a Motion correction (mask)** : âœï¸
  check the automatic centerline detection and the mask used for motion correction, if needed, manually correct the centerline you can modify the line 43 of the run_all_processing.sh:
  ```
  nohup python -u ../code/preprocessing_workflow.py --ids "${IDs[@]}" --redo True --manual_centerline True \
  ```

  The output files can be found in:
  ```
  /spine_7t_fmri_analysis/derivatives/manual/sub-<ID>/func/
      â””â”€â”€ <task*_acq*>/
          â”œâ”€â”€ sub-<ID>_<task_acq>_bold_tmean_centerline.csv
          â””â”€â”€ sub-<ID>_<task_acq>_bold_tmean_centerline.nii.gz

  ```

  - **II Segmentation** âœï¸
  Check the segmentation results, if needed, manually correct the segmentation in FSLeyes using the anatomical image or mean functional image as background.
 When saving the corrected segmentation, make sure to keep the same name as the original segmentation file but save it in the `manual` folder:
  ```
  /spine_7t_fmri_analysis/derivatives/manual/sub-<ID>/func
      â””â”€â”€ <task*_acq*>/
          â””â”€â”€ sub-<ID>_<task_acq>_bold_moco_mean_seg.nii.gz
  ```

  - **III Labeling of inter vertebral disk** âœï¸
  Check the automatic labeling of the inter vertebral disks on the anatomical image, if needed (now default is manual), you can modify the line 43 of the run_all_processing.sh :
  ```
  nohup python -u ../code/preprocessing_workflow.py --ids "${IDs[@]}" --redo True --auto_vert_labels False \
  ```
  The output files can be found in:
  ```
  /spine_7t_fmri_analysis/derivatives/manual/sub-<ID>/anat
      â””â”€â”€ sub-<ID>_T2star_space-orig_label-ivd.nii.gz
  ```
</details>


##### â€¼ï¸ What we want to try to improve
> - **IV. Registration to template:** check if the parameters for the registration are ok.

### 2.2 Denoising  ğŸ§¹

Should be run after preprocessing.
- âš ï¸ csf segmentation should be checked and manually corrected if needed before running the denoising.

#### Description of the denoising steps
- **I. Extract motion parameters:** to regressed out the residual motion effects, we extracted slice-wise motion parameters from the moco files generated during the motion correction step.
- **II. Compute outliers calculation:** to identify volumes with excessive motionas and included as nuisance regressors in the denoising step.
- **III. CompCor calculation:** to eliminate the non-neural aspects of the signal, we used the CompCor (Behzadi et al., 2007) approach by extracting the mean signal and the first five principal components of the unsmoothed signal recorded from the CSF (CSF-mask in functional space).
- **IV. Signal cleaning:** we regressed out the nuisance regressors (motion parameters, outliers, mean CSF signal and first five principal components from the CSF) and applied a high-pass temporal filter (cut-off frequency = 0.01 Hz) to the functional data.

#### Run denoising
- Runs preprocessing steps automatically with output log from STDOUT.
- By default, the steps are not rerun if some outputs already exist.
- If you already have setup `PATH_CODE` and `PATH_DATA`, you don't need to specify `--path-data` and `--path-code`.
- Specify individuals to process (`--ids 090 101 106`) or `IDs=(090 101 106)` and (`--ids "${IDs[@]}"`) , the default option run preprocessing on all participants in the `participants.tsv`. Specify task to denoise (`--tasks` `motor` or `rest`), the default option run denoising on all tasks defined in the `config_file_7t_fmri.json`.

```bash
# ids(090 101 106)
bash "${PATH_CODE}/code/run_all_processing.sh" --path-data "${PATH_DATA}" --path-code "${PATH_CODE}" --ids "${IDs[@]}" --tasks motor --denoising

```

### 2.3 First-level Analysis ğŸ“ˆ
Should be run after preprocessing and denoising.

#### Description of the first-level analysis
- **I. Run first level GLM:** to estimate the activation maps for each condition of interest (e.g., motor task vs rest) using the events files and the denoised functional data. The design matrix includes the conditions of interest.
- **II. Normalize the resulting stat maps to PAM50 template space:** to allow for group-level analyses, we normalized the resulting stat maps to the PAM50 template space using the warps generated during the preprocessing step.

#### Run first-level analysis
- If you already have setup `PATH_CODE` and `PATH_DATA`, you don't need to specify `--path-data` and `--path-code`.
- Specify individuals to process (`--ids 090 101 106`) or `IDs=(090 101 106)` and (`--ids "${IDs[@]}"`) , the default option run preprocessing on all participants in the `participants.tsv`. Specify task to analyse (`--tasks` `motor`), the default option run denoising on all tasks defined in the `config_file_7t_fmri.json` but for this protocol you shoul specify motor task only.
- You add `--firstlevel` to run first level analysis.

```bash
# ids(090 101 106)
bash "${PATH_CODE}/code/run_all_processing.sh" --path-data "${PATH_DATA}" --path-code "${PATH_CODE}" --ids "${IDs[@]}" --tasks motor --firstlevel

```


### 2.4 Figures  ğŸ§¹

Should be run after the first level analysis.

#### Description of the figure steps
- **I. tSNR** Average tSNR maps in the PAM50 template are computed and averaged across participants. Average tSNR in for each participant is also extracted in its native space. 

#### Run figures
- Runs figure generation steps automatically with output log from STDOUT.
- By default, the steps are not rerun if some outputs already exist.
- If you already have setup `PATH_CODE` and `PATH_DATA`, you don't need to specify `--path-data` and `--path-code`.
- Specify individuals to process (`--ids 090 101 106`) or `IDs=(090 101 106)` and (`--ids "${IDs[@]}"`), the default option runs on all participants in the `participants.tsv`. Both tasks need to be used to generate the figures.

```bash
bash "${PATH_CODE}/code/run_all_processing.sh" --path-data "${PATH_DATA}" --path-code "${PATH_CODE}" --ids "${IDs[@]}" --figures

```